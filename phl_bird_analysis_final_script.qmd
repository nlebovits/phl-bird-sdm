---
title: "Sea Level Rise and Avian Biodiversity"
subtitle: "Assessing Projected Impacts in Philadelphia"
description: "ENVS 6611 Final Project"
author: "Nissim Lebovits"
date: today
format: 
  html:
    toc: true
    theme: flatly
editor: visual
execute:
  echo: false
  warning: false
  error: false
  messages: false
---

## Summary
In this project, I explore the potential of using publicly available citizen science data from eBird to asses the threat of sea level rise to bird biodiversity in Philadelphia. Specifically, the John Heinz National Wildlife Refuge, Pennypack on the Delaware, and Bartram's Garden are identified as areas facing a particularly high threat by sea level rise to biodiversity. Future efforts along these lines should focus on improving on the statistical rigor of this analysis and standardizing a streamlined workflow to allow for replication in Philadelphia and other cities, while also striving to interface with local government and community members to translate this model into concrete conservation efforts.

## Introduction

### Background

#### Sea Level Rise and Biodiversity

Sea level rise is one of the most significant and immediate consequences of anthropogenic climate change. In addition to its material impacts on human society, sea level rise threatens global biodiversity. Species will be impacted by increased inundation and storm flooding; coastal erosion; saltwater intrusion; changes to tides and sedimentation; changes to air temperature and rainfall; and further yet unpredictable effects, such as the contraction or expansion of marshes.[^1] Additionally, sea level rise will alter habitat quality in urban coastal areas, which could have large-scale impacts on the areal extent and health of urban ecosystems such as wetlands.[^2]

[^1]: Wilby, R. L., & Perry, G. L. W. (2006). Climate change, biodiversity and the urban environment: a critical review based on London, UK. Progress in Physical Geography: Earth and Environment, 30(1), 76–78. https://doi.org/10.1191/0309133306pp470ra

[^2]: *Urbanization, Biodiversity, and Ecosystem Services: Challenges and Opportunities*, Elmqvist et al., 2013, 497.

Current research suggests that sea level rise will primarily affect tropical biodiversity, especially in South America and various islands habitats. Less research exists on how sea level rise will impact urban biodiversity in North America. Generally speaking, however, research suggests that species with limited ranges will be most impacted, and that species reliant on rare and/or vulnerable coastal habitats will be most threatened.[^3]

[^3]: Elmqvist et al., 496; Wilby and Perry, 73.

#### Philadelphia's Situation

Philadelphia sits at the boundary between the Atlantic Coastal Plain and Piedmont ecoregions. The area was historically covered with hardwood forests, but much of its natural vegetation has been removed for urbanization and cultivation.[^4] Built as a port along the Delaware River, the city was constructed on top of historic wetlands and mudflats. Due to infill and development, 95% of the region's freshwater tidal wetlands have been lost. As a result of Philadelphia's location and development patterns, SLR projections estimate that much of the area adjacent to the Delaware will be under water within the next century.[^5]

[^4]: “Philadelphia, PA and Surrounding Area.” Environmental Protection Agency. Accessed December 20, 2022. https://www.epa.gov/sites/default/files/2019-03/documents/phipa_final.pdf. 

[^5]: “Philadelphia: Urban Ecology and the Balance of Human and Ecological Communities.” Water Center. Accessed December 20, 2022. https://watercenter.sas.upenn.edu/philadelphia-urban-ecology-and-the-balance-of-human-and-ecological-communities/. 

![Elevation of Land in Philadelphia Close to Sea Level](http://maps.risingsea.net/CCSP/D.3_Philadelphia50cm_Titus_and_Wang_2008.jpg){width="50%"}

The city of Philadelphia is also a major hotspot for bird biodiversity in North America. A key migratory stopover location on the [Atlantic Flyway](https://www.audubon.org/atlantic-flyway), Philadelphia sees more than 200 species of migratory birds pass through it each year.[^6] The city hosts a number of regional bird hotspots, especially Pennypack on the Delaware (266 species), John Heinz National Wildlife Reserve (281 species), and FDR Park (313 species).[^7] Given their proximity to the Schuylkill and Delaware rivers, all three of these sites are likely to be significantly impacted by SLR. From a management perspective, it is therefore important to understand the possible impact of SLR on Philadelphia's avian biodiversity.

[^6]: “The Discovery Center.” Audubon Pennsylvania, May 9, 2022. https://pa.audubon.org/chapters-centers/discovery-center. 

[^7]: “Explore Hotspots - Ebird.” Accessed December 20, 2022. https://ebird.org/hotspots. 

![Bird Biodiversity Hotspots in the Philadelphia Region](https://github.com/nlebovits/phl-bird-sdm/blob/main/2022_11_03_ebird_phl_hotspots_screenshot.png?raw=true){fig-align="center"}

Finally, a key motivation for this project is Philadelphia's lack of resources for conservation. Although the city government includes a Parks and Recreation department and an Office of Sustainability, both are notoriously underfunded. The Trust for Public Land calculated that Philadelphia spends 25% less per capita on parks than the national average, with most of that funding directed to recreation, not environmental conservation.[^8] The recently-launched Office of Sustainability nominally has a mandate to work on "quality natural resources", but does not explicity work on conservation.[^9] Much of the conservation work in the city is left to volunteer organizations like the [Philly Forest Stewards](https://loveyourpark.org/volunteer/forest-stewards), or non-profits like [Friends of the Wissashickon](https://fow.org/). Given the limited capacity of governmental, non-profit, and community organizations, there is an evident use for tools to support more efficient, cost-effective monitoring and interventions.

[^8]: “2022 Sea Level Rise Technical Report.” NOAA's National Ocean Service, February 15, 2022. https://oceanservice.noaa.gov/hazards/sealevelrise/sealevelrise-tech-report.html. 

[^9]: “Office of Sustainability: Homepage.” City of Philadelphia, December 13, 2022. https://www.phila.gov/departments/office-of-sustainability/. 

#### Data Sources

This project uses two primary data sources: citizen science bird observations from eBird, and NOAA's sea level rise projections.

##### eBird Data

This project focuses on bird biodiversity for two reasons. First, birds are strong indicator species. Although it is not clear that bird populations alone are an effective measure of ecosystem health, they are the best-studied indicator of urban biodiversity, and their role in supporting a larger ecosystem is critical.[^10] Second, an abundance of quality data on bird biodiversity are publicly available from sources like the [Cornell Ornithology Lab's eBird](https://ebird.org/about), and recent studies have demonstrated the effectiveness of using these citizen science data to evaluate bird biodiversity. [^11] Because these data are publicly available and well-documented, they are valuable for low-cost conservation, especially from the perspective of under-resourced local governments such as Philadelphia's.

[^10]: McDonnell, M.J., Hahs, A.K. "The use of gradient analysis studies in advancing our understanding of the ecology of urbanizing landscapes: current status and future directions". Landscape Ecol. vol. 23, 2008, pp. 1143--1155; Oostermeijer, Gegard. "Methods for studying urban biodiversity" in Seeing the City: Interdisciplinary Perspectives on the Study of the Urban Book. Edited by Nanke Verloo and Luca Bertolini. Amsterdam: Amsterdam University Press, 2020; Bairlein, Franz. "Introduction." Ecology and Conservation of Birds in Urban Environments, edited by Enrique Murgui and Marcus Hedblom, Cham, Switzerland, Spring International Publishing, 2017, pp. v--vi; Morelli, F., Y. Benedetti, and C. T. Callaghan. "Ecological specialization and population trends in European breeding birds". Global Ecology and Conservation, vol. 22, 2020, e00996. Link to paper

[^11]: Callaghan, C. T., M. B. Lyons, J. M. Martin, R. E. Major, and R. T. Kingsford. "Assessing the reliability of avian biodiversity measures of urban greenspaces using eBird citizen science data". Avian Conservation and Ecology, vol. 12, no.2, 2017, pp.12. https://doi.org/10.5751/ACE-01104-120212; Callaghan, C. T., J. H. Wilshire, J. M. Martin, R. E. Major, M. B. Lyons, and R. T. Kingsford. "The Greenspace Bird Calculator: a citizen-driven tool for monitoring avian biodiversity in urban greenspaces". Australian Zoologist, vol. 40, 2020, pp. 468-476.

One key caveat with eBird data is the impact of pandemic birding. The extraordinary and unprecedented rise in citizen science data collection during the pandemic has been a boon for ecological data. However, it also complicates the interpretation of these data. As Sara Harrison explains in *Wired*, "Scientists can't always tell whether changes in the data are due to animal behavior or just an increase in the amount of information available. Furthermore, "It's not just that more people are observing---it's also a matter of where they are observing."[^12] Observations in urban areas have increased, while observations in rural areas have decreased, suggesting likely undersampling in less-accessible habitats. As I will explain in the Data Wrangling and Exploration section, this issue must be accounted for.

[^12]: Sara Harrison, "Pandemic Bird-Watching Created a Data Boom-and a Conundrum," Wired (Conde Nast, September 30, 2021), https://www.wired.com/story/pandemic-bird-watching-created-a-data-boom-and-a-conundrum/

##### NOAA Data

Data on sea level rise projections in Philadelphia comes from the National Ocean and Atmospheric Administration and are [available for all 50 states](https://coast.noaa.gov/slrdata/). It offers a range of scenarios, from "low" to "high". As explained on the website,

> \[The relative sea level rise (RSL) scenarios\] are derived from the 2022 Sea Level Rise Technical Report using the same methods as the U.S. Army Corps of Engineers Sea Level Change Curve Calculator. These new scenarios were developed by the U.S. Sea Level Rise and Coastal Flood Hazard Scenarios and Tools Interagency Task Force as input into the U.S. Global Change Research Program Sustained Assessment process and, Fifth National Climate Assessment. These RSL scenarios provide an update to the NOAA 2017 scenarios, which were developed as input to the Fourth National Climate Assessment.[^13]

[^13]: “NOAA Logo Sea Level Rise Viewer.” View site. Accessed December 20, 2022. https://coast.noaa.gov/slr/#/layer/slr/10/-8376235.061842223/4852224.4720263705/14/dark/192/0.8/2050/inter/midAccretion. 

Further information on the technical details is available in the [2022 Sea Level Rise Technical Report](https://oceanservice.noaa.gov/hazards/sealevelrise/sealevelrise-tech-report.html).

This project maps most of those scenarios, with some important caveats. First, the NOAA data include both sea level rise projections and sunny day high tide flooding projections. Although the latter is an important impact of sea level rise, temporary flooding and permanent inundation have different (and potentially conflicting) impacts on biodiversity and therefore must be considered separately. For the sake of simplicity given the limited scope of this project, then, I have only explored sea level rise, not sunny day high tide flooding.

Second, I have excluded data for rates of sea level rise that are unlikely to happen in Philadelphia. Although NOAA data include up to 10 feet of sea level rise, their projections for even the worst scenario in Philadelphia max out at 6.59 feet of sea level rise. Therefore, I have included only the likey 1 foot, 2 foot, and 3 foot scenarions and the worst-case scenario of 7 feet of rise. In the clustering analysis later in the report, I used the 1 foot projection for sea level rise, as this is what NOAA considers the "intermediate" scenario likely to occur by 2040, which is the first post-2022 date for which they have projections.

##### Evaluating Biodiveristy in an Urban Context

One of the unique challenges of this project is that it focuses on an urban context. Analyzing biodiversity in general is complicated, as all environmental systems are. But urban environments add special complications that disrupt some of the normal approaches and assumptions of biodiversity modeling. Urban environments introduce variables that do not exist in "natural" spaces, such as human population density and abrupt fragmentation and changes in land use type. The scales, boundaries, and definitions of various types of data can be hard to reconcile as well. Furthermore, prediction becomes even more difficult in urban contexts where factors such as population density, buildout, and impervious surface cover can change rapidly and unexpectedly, even in the course of a few years. (This poses a particular challenge for sea level rise, flooding, and related issues like stormwater management.) Arguably, it is more difficult to evaluate biodiversity in urban contexts than in "natural" environments. There are efforts to address this, however, many of which are discussed in *Urbanization, Biodiversty, and Ecosystem Services: Challenges and Opportunities*, by Elmqvist et al.[^14] In fact, efforts to use citizen science data to improve monitoring, analysis, and management are key to improving the health of urban biodiversity. As explained in the chapter on "Indicators for Management of Urban Biodiversity and Ecosystem Services",

[^14]: Elmqvist et al., 2013.

> \[The City Biodiversity Index\] can provide incentives for municipalities to start making inventories and monitoring programs of their biodiversity. For example, it is today possible to integrate remote sensing data and in situ observations to monitor several essential biodiversity variables such as habitat structure and phenology. ... In this context, municipalities should explore the possibilities of launching citizen science projects and consider the possibility in general that within cities local knowledge on biodiversity and ecosystem services may reside in many different groups within civic society.[^15]

[^15]: Sara Harrison, "Pandemic Bird-Watching Created a Data Boom-and a Conundrum," Wired (Conde Nast, September 30, 2021), https://www.wired.com/story/pandemic-bird-watching-created-a-data-boom-and-a-conundrum/.

### Project Goals

The goal of this project is to explore the potential of using publicly available citizen science data to assess the impacts of sea level rise on avian biodiversity in Philadelphia. The primary focus is to demonstrate that eBird data can be applied to conservation management in an urban context. Secondarily, this project aims to identify the biodiversity hotspots in Philadelphia that will be most heavily impacted by sea level rise in the coming years. Lastly, it hopes to identify potential next steps and applications for the workflow and approaches employed here.

## Data Wrangling and Exploration

```{r setup}

library(tidyverse)
library(ggplot2)
library(sf)
library(janitor)
library(lubridate)
library(tmap)
library(mapview)
library(janitor)
library(plotly)
library(ggthemr)
library(auk)
library(ggpubr)
library(ggrepel)
library(readxl)
library(dbscan)
library(ggExtra)
library(BAMMtools)
library(RColorBrewer)
library(classInt)

ggthemr("pale") #set global ggplot theme

options(scipen = 999) # turn off scientific notation

tmap_options(basemaps = "Esri.WorldTopoMap", basemaps.alpha = 0.7)
```

```{r clean and import}
#| include: false
#| cache: true

ebird = read.table("C:/Users/Nissim/Desktop/Fall 2022/Floodplain Management/Final Project Data/eBird/ebd_US-PA-101_relSep-2022.txt",
           sep = "\t", 
           header = TRUE,
           fill = TRUE) |>
           clean_names()|>
           filter(protocol_type %in% c("Stationary", "Traveling")) |> # restrict to the standard traveling and stationary count protocols 
           auk_unique() #filter for only unique checklists to avoid duplicates created by groups

ebird_i = ebird |>
            dplyr::select(taxonomic_order,
                          category,
                          taxon_concept_id,
                          common_name,
                          scientific_name,
                          exotic_code,
                          observation_count,
                          breeding_code,
                          breeding_category,
                          county_code,
                          locality,
                          locality_id,
                          latitude,
                          longitude,
                          observation_date,
                          time_observations_started,
                          observer_id,
                          approved,
                          effort_distance_km,
                          number_observers,
                          protocol_type,
                          duration_minutes,
                          sampling_event_identifier) |>
            dplyr::filter(approved == "1") # make sure R doesn't confuse dplyr::filter with stats::filter

# function to convert time observation to hours since midnight
# pulled directly from https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html#ebird-zf
time_to_decimal <- function(x) {
  x <- hms(x, quiet = TRUE)
  hour(x) + minute(x) / 60 + second(x) / 3600
}

ebird_i$observation_date = as_date(ebird_i$observation_date)

ebird_i = ebird_i |>
            mutate(
              # convert X to NA
              observation_count = if_else(observation_count == "X", 
                                          NA_character_, observation_count),
              observation_count = as.integer(observation_count),
              # effort_distance_km to 0 for non-travelling counts
              effort_distance_km = if_else(protocol_type != "Traveling", 
                                           "0", effort_distance_km),
              # convert time to decimal hours since midnight
              time_observations_started = time_to_decimal(time_observations_started),
              # split date into year and day of year
              year = year(observation_date),
              day_of_year = yday(observation_date)
            ) |>
          filter(
            # effort filters
            duration_minutes <= 5 * 60,
            effort_distance_km <= 5,
            # last 10 years of data
            year >= 2010,
            # 10 or fewer observers
            number_observers <= 10)

ebird_last_decade = ebird_i |>
                      filter(year >= 2012 & year <= 2021)

iucn = read_excel("C:/Users/Nissim/Desktop/Fall 2022/Floodplain Management/Final Project Data/Handbook of the Birds of the World and BirdLife International Digital Checklist of the Birds of the World_Version_6b.xlsx")

colnames(iucn) = iucn[2, ]

iucn = iucn[-c(1,2), ]

iucn = iucn |>
        clean_names() |>
        filter(!is.na(order)) |>
        select(scientific_name,
               x2022_iucn_red_list_category)

ebird_last_decade = left_join(ebird_last_decade, iucn, by = "scientific_name")


#all obsvs
countXyearXspecies = aggregate(data = ebird_last_decade,                # Applying aggregate
                          scientific_name ~ year,
                          function(scientific_name) length(unique(scientific_name)))

countXyearXsei = aggregate(data = ebird_last_decade,                # Applying aggregate
                          sampling_event_identifier ~ year,
                          function(sampling_event_identifier) length(unique(sampling_event_identifier)))

unique_per_chklst = countXyearXspecies |>
                      select(-year) |>
                      cbind(countXyearXsei)

#nt obsvs
nt_countXyearXspecies = aggregate(data = (ebird_last_decade |> filter(x2022_iucn_red_list_category == "NT")),                # Applying aggregate
                          scientific_name ~ year,
                          function(scientific_name) length(unique(scientific_name)))

nt_countXyearXsei = aggregate(data = (ebird_last_decade |> filter(x2022_iucn_red_list_category == "NT")),                # Applying aggregate
                          sampling_event_identifier ~ year,
                          function(sampling_event_identifier) length(unique(sampling_event_identifier)))

nt_unique_per_chklst = nt_countXyearXspecies |>
                      select(-year) |>
                      cbind(nt_countXyearXsei)

#vul obsvs
vu_countXyearXspecies = aggregate(data = (ebird_last_decade |> filter(x2022_iucn_red_list_category == "VU")),                # Applying aggregate
                          scientific_name ~ year,
                          function(scientific_name) length(unique(scientific_name)))

vu_countXyearXsei = aggregate(data = (ebird_last_decade |> filter(x2022_iucn_red_list_category == "VU")),                # Applying aggregate
                          sampling_event_identifier ~ year,
                          function(sampling_event_identifier) length(unique(sampling_event_identifier)))

vu_unique_per_chklst = vu_countXyearXspecies |>
                      select(-year) |>
                      cbind(vu_countXyearXsei)

sd_upc = sd(unique_per_chklst$scientific_name)

mean_upc = mean(unique_per_chklst$scientific_name)

upc_2021 = unique_per_chklst$scientific_name[unique_per_chklst$year == 2021]

upc_2021_above_mean = round((upc_2021 - mean_upc) / sd_upc, digits = 2)


## spatial

ebird_sf = sf::st_as_sf(ebird_last_decade,
                        coords = c("longitude",
                                   "latitude"),
                        crs = st_crs("EPSG:4326")) |>
  st_transform(st_crs("EPSG:2272")) #NAD83/PA South (ftUS)

# import phl boundaries to generatte a grid
phl_bounds = st_read("C:/Users/Nissim/Desktop/Fall 2022/Spat Stats/phl_city_limits/City_Limits.shp") |>
  st_transform(crs = st_crs(ebird_sf))

phl_grid <- phl_bounds %>%
  st_make_grid(st_bbox(.), square = FALSE, cellsize = 2640) %>% #currently using half mile cells
  st_sf() %>% 
  mutate(hex_id = row_number())

phl_grid = phl_grid[phl_bounds,]

ebird_sf = st_join(ebird_sf, phl_grid)


# so I need:
  # unique species per cell
  # checklists per cell

unique_species_per_hex = ebird_sf |>
                  st_drop_geometry() |>
                  aggregate(scientific_name ~ year + hex_id,
                          function(scientific_name) length(unique(scientific_name))) |>
                  rename(unique_species = scientific_name)

checklsits_per_hex = ebird_sf |>
                  st_drop_geometry() |>
                  aggregate(sampling_event_identifier ~ year + hex_id,
                          function(sampling_event_identifier) length(unique(sampling_event_identifier))) |>
                  rename(unique_sei = sampling_event_identifier)

per_hex = left_join(unique_species_per_hex, (checklsits_per_hex |> select(-year))) |>
              mutate(unique_per_sei = unique_species / unique_sei)|>
                    group_by(hex_id) |>
                    summarize(avg_unique_species = mean(unique_species, na.rm = TRUE),
                              avg_unique_per_sei = mean(unique_per_sei, na.rm = TRUE))


phl_ebird_hex_means = left_join(phl_grid, per_hex, by = "hex_id")

phl_ebird_hex_means$avg_unique_species[is.na(phl_ebird_hex_means$avg_unique_species)] = 0
phl_ebird_hex_means$avg_unique_per_sei[is.na(phl_ebird_hex_means$avg_unique_per_sei)] = 0



# now repeat the same thing with vulnerable species only

vu_unique_species_per_hex = ebird_sf |>
                  filter(x2022_iucn_red_list_category == "VU") |>
                  st_drop_geometry() |>
                  aggregate(scientific_name ~ year + hex_id,
                          function(scientific_name) length(unique(scientific_name))) |>
                  rename(unique_species = scientific_name)

vu_checklsits_per_hex = ebird_sf |>
                  filter(x2022_iucn_red_list_category == "VU") |>
                  st_drop_geometry() |>
                  aggregate(sampling_event_identifier ~ year + hex_id,
                          function(sampling_event_identifier) length(unique(sampling_event_identifier))) |>
                  rename(unique_sei = sampling_event_identifier)

vu_per_hex = left_join(vu_unique_species_per_hex, (vu_checklsits_per_hex |> select(-year))) |>
              mutate(unique_per_sei = unique_species / unique_sei)|>
                    group_by(hex_id) |>
                    summarize(avg_unique_species = mean(unique_species, na.rm = TRUE),
                              avg_unique_per_sei = mean(unique_per_sei, na.rm = TRUE))


vu_phl_ebird_hex_means = left_join(phl_grid, vu_per_hex, by = "hex_id")

vu_phl_ebird_hex_means$avg_unique_species[is.na(vu_phl_ebird_hex_means$avg_unique_species)] = 0
vu_phl_ebird_hex_means$avg_unique_per_sei[is.na(vu_phl_ebird_hex_means$avg_unique_per_sei)] = 0
```

### Bird Biodiversity

#### Wrangling

A number of steps were necessary to render eBird's raw data usable. After downloading the data from the eBird website, I followed the workflow laid out in the [Cornell Ornithology Lab's guide to using eBird data](https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html), with some modifications specific to this project.

Based on their recommendations, I filtered out eBird checklists over 5 hours long, over 5 km in length, or with more than 10 observers. I also only looked at data between 2012 and 2021 (the last ten full years) and filtered only for eBird "approved" checklists. Additionally, I downloaded the [International Union for Conservation of Nature](https://www.iucnredlist.org/)'s (IUCN) [redlist data on threatened bird species](http://datazone.birdlife.org/userfiles/file/Species/Taxonomy/HBW-BirdLife_Checklist_v6b_Jul22.zip), which I then joined to the eBird dataset for later analysis.

Finally, I aggregated point observations to a grid of 0.5 kilometer hexagons covering Philadelphia. This is the approach recommended by the Cornell Ornithology lab for handling the imprecision of point observations. Although they use 5 km bins in their analysis, they are considering a much larger spatial scale (the southeastern United States). Such large bins are inappropriate for an urban scale, so I opted for 0.5 kilometer hexagons based on trial and error. (In future, more rigorous versions of a project like this, it would be better to identify ideal hexagon sizes [based on a more statistically sophisticated analysis](https://www.azavea.com/blog/2020/09/04/choosing-cell-size-for-point-pattern-analysis/)). Visualizations for these aggregations are visible in the Mapping section below.


#### Exploration

##### Observations vs. Effort

As explained above in the Introduction, eBird data have been
distorted by the rise in reporting during the pandemic. To account for this, we
must first compare the number of observations per year as a function of effort.
In this case, the eBird indicator for unique checklists can be treated as a
representation of effort spent per observation. A checklist represents a single
observation event (a birding outing), and groups together sightings of multiple
species from the same observation event.^[Matthew Strimas-Mackey, Wesley M. Hochachka. “Best Practices for Using EBird Data.” Chapter 1 Introduction and Setup. Accessed December 20, 2022. https://cornelllabofornithology.github.io/ebird-best-practices/intro.html.]

Comparing data on observations and checklists from 2012
through 2021, we can see that both observations per year and checklists per
year trended upward in general from 2021 to 2021, with a substantial increase in
2021. Therefore, we suspect that the increase in observations in Philadelphia
was a function of the increased effort spent by birders, which we must account
for in our estimation of avian biodiversity in the city.

```{r annual observations tally}
obsvs = ggplot(ebird_last_decade, aes(year)) +
  geom_bar() +
  labs(title = "Annual Observations",
       subtitle = "2012-21",
       x = "Year",
       y = "Total Observations") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

chklsts = ggplot(countXyearXsei) +
  geom_col(aes(x = year, y = sampling_event_identifier)) +
  labs(title = "Annual Sampling Events",
       subtitle = "2012-21",
       x = "Year",
       y = "Total Sampling Events")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

ggarrange(obsvs, chklsts)
```

##### Estimating Biodiversity

The primary focus of our analysis here is *species richness*: the total number of unique species within our study region.^[ “Species Richness.” Species Richness - an overview | ScienceDirect Topics. Accessed December 20, 2022. https://www.sciencedirect.com/topics/earth-and-planetary-sciences/species-richness. ]

```{r unique per year}
ggplot(unique_per_chklst, aes(y = scientific_name, x = year)) +
    geom_col() +
    coord_cartesian(ylim = c(200, 300)) +
    labs(title = "Unique Species per Year",
         subtitle = '2012-21',
       x = "Year",
       y = "Unique Species")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

The data indicate an increase in the number of unique
species observed in Philadelphia per year over the last decade. But, as noted
above, this uptick is likely related to the increase in effort. Simply put,
more effort spent by birders means that more unique species are likely to be
observed. However, this increase is asymptotic---there is a limit to the number
of unique species that are likely in Philadelphia. In ecology, this maximum
limit can be estimated using an asymptotic function known as a
species-accumulation curve, or a rarefaction curve:

> Biologists often interpret species-survey data by examining the number of species found as a function of effort, plotted as a species-accumulation curves (SAC). The SAC plots the cumulative number of species recorded as a function of sampling effort (i.e. number of individuals collected or cumulative number of samples). At the start of a species survey, the total number of species found typically grows quickly with every unit of effort. After some time, however, effort expended yields more and more species that have already been found earlier in the survey---and the total number of species grows more slowly per unit of effort. A plot of species number vs effort will come to a plateau, and this saturation level is a common estimator for the number of species in an area.[^16]

[^16]: Jiménez-Valverde, A. & Lobo, Jorge & Hortal, Joaquín. (2009). The effect of prevalence and its interaction with sample size on the reliability of species distribution models. Community Ecology. 10. 196-205. 10.1556/ComEc.10.2009.2.9.

Ideally, a rarefaction curve could be used to estimate
global biodiversity in Philadelphia and even local biodiversity at a
neighborhood level. Because this technique lies outside of my current
abilities, I've performed a very rudimentary estimation of rarefaction using
another asymptotic function, a quadratic equation.

```{r unique per chklst plt}

ggplot(unique_per_chklst, aes(x = sampling_event_identifier, y = scientific_name, label = year)) +
    geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, aes(col = "Quadratic")) +
    geom_smooth(method = "lm", se = FALSE, linetype = 'dashed', aes(col = "Linear")) +
    geom_point()+
    geom_label_repel(size = 2.5) +
    scale_colour_manual(name = "Model", values = c("#5E2C25", "#C8E370")) +
    labs(title = "Unique Species vs. Total Checklists",
         subtitle = '2012-21',
       x = "Total Sampling Events",
       y = "Unique Species")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "bottom")
```

To be clear, this is not a perfect estimate of actual
biodiversity in Philadelphia, and should not be taken as a precise measure.
However, it gives a general qualitative idea of how many unique bird species
may be resident or pass through Philadelphia (around 290). As more data are
reported in 2022 and beyond, this estimation should become more accurate.
Ideally, proper rarefaction could be performed by a quantitative ecologist, but
for now, this will suffice.

##### Identifying Vulnerable Species

One common issue with urban bird biodiversity is
that, while the total number of unique species may stay the same as before
urbanization, or even increase, this often elides an underlying shift in the
composition of biodiversity. Frequently, vulnerable species endemic to local
habitats are outcompeted by invasive generalists, which can increase statistical species
richness while harming native biodiversity.^[Ibanez-Alamo, Rubio Diego. “Global Loss of Avian Evolutionary Uniqueness in Urban Areas.” Global change biology, vol. 23, no. 8, 2017, 2990–2998.] To account for this, we can use
IUCN data to look at the composition of reported biodiversity per year.

In the graph below, "LC" refers to species of least
concern, "NT" to near-threatened species (a step below vulnerable species), and "VU" to vulnerable species.^[“Terms &amp; Definitions - IUCN Red List Categories .” Birdlife Data Zone. Accessed December 20, 2022. http://datazone.birdlife.org/species/spcredcat. ] Observations not matching any taxonomy in the IUCN list have been filtered out. As the graph shows, species of least concern have made up roughly 96-97% percent of observations in any given year, near threatened species another 1.5-2%, and vulnerable species around 1-1.5% (mouse over the interactive graph to see specific numbers for each year).


```{r iucn}
prop_palette = c("#3262AB", "#C8E370", "#FF8D7D")


ggplotly(ggplot(data = (ebird_last_decade |> filter(x2022_iucn_red_list_category %in% c("LC", "NT","VU"))),
       aes(year, fill = forcats::fct_rev(x2022_iucn_red_list_category))) +
geom_bar(position = "fill") +
scale_y_continuous(labels = scales::percent) +
scale_fill_manual(values = prop_palette) +
coord_cartesian(ylim = c(0, 1)) +
labs(title = "IUCN Red List Observations by Category per Year",
       x = "Year",
       y = "Percent of Total Observations",
       fill = "IUCN Category")+
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle=45, hjust=1, size = 7),
        axis.text.y = element_text(size = 7),
        axis.title.x = element_blank()))
```

As before, we can plot observations against effort. This time, however, the number of observations is too low to give even an approximation of a rarefaction curve. In every year between 2021 and 2021, the number of observed vulnerable species was either 3 or 4. On a practical level, we may assume that this is the approximate number of vulnerable bird species in Philadelphia, but this is a *very* rough estimate that ought to be subjected to more robust statistical analysis.

```{r vul unique per chklst plt}

ggplot(vu_unique_per_chklst, aes(x = sampling_event_identifier, y = scientific_name, label = year)) +
    geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, aes(col = "Quadratic")) +
    geom_smooth(method = "lm", se = FALSE, linetype = 'dashed', aes(col = "Linear")) +
    geom_point()+
    geom_label_repel(size = 2.5) +
  coord_cartesian(ylim = c(2, 5)) +
    scale_colour_manual(name = "Model", values = c("#5E2C25", "#C8E370")) +
    labs(title = "Unique Vulnerable Species vs. Total Checklists",
         subtitle = '2012-21',
       x = "Total Sampling Events",
       y = "Unique Species")+
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "bottom")
```

### Sea Level Rise

#### Wrangling

Below, sea level rise data were aggregated to the same
hexagon grid as eBird observations. Each cell counts the total area of sea
level rise under the given sea level rise scenario. This follows the Cornell
Ornithology Lab\'s approach. 

The NOAA data report projected mean highest-high water levels, meaning that they *include* current bodies of water such as the Delaware River. To calculate projected additional inundation, I subtracted the area of current MHHW levels per hexagon from the projected area per hexagon in each future scenario (e.g., current MHHW minus MHHW with 1 foot of sea level rise). This led to challenges with visualization, since the maximum projected additional inundation with 1 foot of sea level rise was 5.6%, while the maximum projected additional inundation with 7 feet of sea level rise was 93.9%. 

```{r slr import}
#| include: false
#| cache: true

# create object that has path to gdb
gdb_path = 'C:/Users/Nissim/Desktop/Fall 2022/Floodplain Management/Final Project Data/NOAA/PA_slr_final_dist.gdb'

# list all the layers (why its not a data frame idk)
all_layers <- st_layers(gdb_path)

# find all polygon fcs 
poly_index <- which(stringr::str_detect(unlist(all_layers[["geomtype"]]), "Polygon"))

all_polygons <- purrr::map(
  all_layers[["name"]][poly_index],
  ~st_read(gdb_path, layer = .x) |>
  st_transform(crs = st_crs(ebird_sf)) |>
  st_make_valid()
)


 calculate_overlap <- function(polygon, ephl_bird_hex_means, id) {
  # this function assumes that the hex_id and Shape Area 
  # are always available in the respective sf object
  # assign an id 
    st_intersection(phl_ebird_hex_means, polygon) |> 
    as_tibble()|>
    mutate(area = as.numeric(st_area(geometry))) |>
    group_by(hex_id)|>
    summarise(area = sum(area),
              id = {{ id }})
          }


# the id is the index of the iteration here (imap == index map)
overlapping_areas <- purrr::imap(
  all_polygons[12:22],  ~calculate_overlap(.x, phl_ebird_hex_means, .y) #only need 0 to 7ft slr scenarios
  )

# squish them all together 
areas_by_id <- bind_rows(overlapping_areas) |> 
  # spread them so that each column is an id
  # and the value is the area
  tidyr::pivot_wider(names_from = "id",
                     values_from = "area",
                     names_prefix = "polygon_")

# join back to the hexagons
phl_ebird_hex_means = left_join(phl_ebird_hex_means, areas_by_id)

phl_ebird_hex_means = phl_ebird_hex_means |>
                      mutate(hex_area = as.numeric(st_area(geometry)),
                             pct_SLR_0ft = polygon_1 / hex_area * 100, #note that polygon_13 is actually 10ft slr--exclude it
                             pct_SLR_1ft = polygon_3 / hex_area * 100,
                             pct_SLR_2ft = polygon_4 / hex_area * 100,
                             pct_SLR_3ft = polygon_5 / hex_area * 100,
                             pct_SLR_4ft = polygon_6 / hex_area * 100,
                             pct_SLR_5ft = polygon_7 / hex_area * 100,
                             pct_SLR_6ft = polygon_8 / hex_area * 100,
                             pct_SLR_7ft = polygon_9 / hex_area * 100,
                             pct_SLR_8ft = polygon_10 / hex_area * 100,
                             pct_SLR_9ft = polygon_11 / hex_area * 100,
                             pct_SLR_10ft = polygon_2 / hex_area * 100)

## order here matters

# first calculate % inundation excluding what is currently part of the rivers

phl_ebird_hex_means$tot_pct_SLR_1ft = phl_ebird_hex_means$pct_SLR_1ft - phl_ebird_hex_means$pct_SLR_0ft
phl_ebird_hex_means$tot_pct_SLR_2ft = phl_ebird_hex_means$pct_SLR_2ft - phl_ebird_hex_means$pct_SLR_0ft
phl_ebird_hex_means$tot_pct_SLR_3ft = phl_ebird_hex_means$pct_SLR_3ft - phl_ebird_hex_means$pct_SLR_0ft
phl_ebird_hex_means$tot_pct_SLR_7ft = phl_ebird_hex_means$pct_SLR_7ft - phl_ebird_hex_means$pct_SLR_0ft

# then replace 0 values with 999

phl_ebird_hex_means$tot_pct_SLR_1ft[phl_ebird_hex_means$tot_pct_SLR_1ft == 0] = 999
phl_ebird_hex_means$tot_pct_SLR_2ft[phl_ebird_hex_means$tot_pct_SLR_2ft == 0] = 999
phl_ebird_hex_means$tot_pct_SLR_3ft[phl_ebird_hex_means$tot_pct_SLR_3ft == 0] = 999
phl_ebird_hex_means$tot_pct_SLR_7ft[phl_ebird_hex_means$tot_pct_SLR_7ft == 0] = 999

# then replace NAs with 0

phl_ebird_hex_means$tot_pct_SLR_1ft[is.na(phl_ebird_hex_means$tot_pct_SLR_1ft)] = 0
phl_ebird_hex_means$tot_pct_SLR_2ft[is.na(phl_ebird_hex_means$tot_pct_SLR_2ft)] = 0
phl_ebird_hex_means$tot_pct_SLR_3ft[is.na(phl_ebird_hex_means$tot_pct_SLR_3ft)] = 0
phl_ebird_hex_means$tot_pct_SLR_7ft[is.na(phl_ebird_hex_means$tot_pct_SLR_7ft)] = 0

# finally, replace 999 with NA
phl_ebird_hex_means$tot_pct_SLR_1ft[phl_ebird_hex_means$tot_pct_SLR_1ft == 999] = NA
phl_ebird_hex_means$tot_pct_SLR_2ft[phl_ebird_hex_means$tot_pct_SLR_2ft == 999] = NA
phl_ebird_hex_means$tot_pct_SLR_3ft[phl_ebird_hex_means$tot_pct_SLR_3ft == 999] = NA
phl_ebird_hex_means$tot_pct_SLR_7ft[phl_ebird_hex_means$tot_pct_SLR_7ft == 999] = NA

breaks = c(0, 0.05, 0.1, 0.5, 1, 2, 5, 10, 25, 50, 75, 100) # breaks for color palette 
```

#### Exploration
```{r slr histograms}

hist_1ft = ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_1ft)) +
              geom_histogram() +
              labs(title = "1 Ft. Sea Level Rise",
       subtitle = "Pct. SLR Impact per Hexagon",
                   x = "Percent Sea Level Rise",
                   y = "Count of Hexagons") +
              theme(plot.title = element_text(hjust = 0.5),
                    plot.subtitle = element_text(hjust = 0.5))

hist_2ft = ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_2ft)) +
  geom_histogram() +
  labs(title = "2 Ft. Sea Level Rise",
       subtitle = "Pct. SLR Impact per Hexagon",
       x = "Percent Sea Level Rise",
       y = "Count of Hexagons") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        axis.title.y = element_blank())

hist_3ft = ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_3ft)) +
  geom_histogram() +
  labs(title = "3 Ft. Sea Level Rise",
       subtitle = "Pct. SLR Impact per Hexagon",
       x = "Percent Sea Level Rise",
       y = "Count of Hexagons") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

hist_4ft = ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_7ft)) +
  geom_histogram() +
  labs(title = "7 Ft. Sea Level Rise",
       subtitle = "Pct. SLR Impact per Hexagon",
       x = "Percent Sea Level Rise",
       y = "Count of Hexagons") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        axis.title.y = element_blank())

ggarrange(hist_1ft, hist_2ft,
          hist_3ft, hist_4ft)
```
For ease of comparison, I designated fixed breaks for all four scenarios based on the distribution of percent sea level rise in all four cases: 

* 0 to 0.05% 
* 0.05 to 0.1% 
* 0.1 to 0.5%
* 0.5 to 1% 
* 1 to 2% 
* 2 to 5% 
* 5 to 10% 
* 10 to 25% 
* 25 to 50% 
* 50 to 75% 
* 75 to 100%

### Mapping

#### Biodiversity Hotspots

In order to understand the geography of bird biodiversity in
Philadelphia, it is important to map the distribution of observations. A
principal obstacle to mapping is that eBird observations are imprecise; they
are reported *close* to where the bird was observed, but not always at the
exact spot, which makes presence/absence models, or continuous distribution
mapping such as kernel density estimates, difficult to impossible. To account
for this, the Cornell Ornithology Lab suggests binning data in a city-wide
grid, which is the approach taken here. Binning further reduces the issue of
spatial bias:

> Spatial bias: most participants in citizen science surveys sample near their homes (Luck et al. 2004), in easily accessible areas such as roadsides (Kadmon, Farber, and Danin 2004), or in areas and habitats of known high biodiversity (Prendergast et al. 1993). A simple method to reduce the spatial bias that we describe is to create an equal area grid over the region of interest, and sample a given number of checklists from within each grid cell.^[Strimas-Mackey and Hochachka]

In the maps below, we map biodiversity by looking at the
average number of unique species per hexagon cell per year. This is, again, not
a perfect estimate of biodiversity. Rarefaction would be helpful, for instance,
to avoid the issue of over/under-sampling. As a general estimate of relative
biodiversity, however, such an approach allows us to understand hotspots and
coldspots. Recalling from above that research suggests that
already-vulnerable species reliant on rare and/or vulnerable coastal habitats
will be most threatened, we can also take the same approach by looking only at
the average number of unique *vulnerable* species observed per cell per year.

Comparing the maps side by side, we can see that the general
shape of the hotspots as similar, and the hotspots near the Delaware River and
in South Philadelphia stand out as key points of overlap between the two maps.
This suggests that those are especially important hotspots of bird
biodiversity. Again, we have to be mindful of diminishing marginal returns on observations and the likelihood of undersampling in some of these areas. The best indication of true vulnerable biodiversity is probably a comparison of average unique species per hexagon and average unique species. This could, again, be improved by employing local rather than global rarefaction, but that is beyond the scope of the current project.
 
:::: {.columns}

::: {.column width="45%"}
###### **Avg. Unique Species**
```{r hotspots}
tmap_mode('view')

tm_shape(phl_ebird_hex_means) + 
                  tm_polygons(title = "Avg. Species",
                              col = "avg_unique_species", 
                              style = "jenks", 
                              palette = "viridis", 
                              alpha = 0.7, 
                              id = "hex_id",
                              popup.vars = c("Avg. Unique Species" = "avg_unique_species")) +
                  tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')

```
:::

::: {.column width="10%"}
<!-- empty column to create gap -->
:::

::: {.column width="45%"}
###### **Avg. Unique Vulnerable Species**
```{r vul hotspots}
tmap_mode('view')

tm_shape(vu_phl_ebird_hex_means) + 
                  tm_polygons(title = "Avg. Species",
                              col = "avg_unique_species", 
                              style = "jenks", 
                              palette = "viridis", 
                              alpha = 0.7, 
                              id = "hex_id",
                              popup.vars = c("Avg. Unique Species" = "avg_unique_species")) +
                  tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')
```
:::

::::



#### Sea Level Rise
In the maps below, we explore the various possible sea level rise scenarios in Philadelphia projected by NOAA for the next 100 years, ranging from 1 ft (the most likely scenario by 2040) to 7 ft (the worst-case scenario by 2100). As mentioned above, the color breaks for the visualization are based on the distribution of data in all four scenarios.

###### **1 Foot of Sea Level Rise**
```{r 1 ft}
tmap_mode('view')

tm_shape(phl_ebird_hex_means) +
  tm_polygons(
              title = "Pct. Inundation",
              col = 'tot_pct_SLR_1ft', 
              palette = 'viridis', 
              style = 'fixed',
              breaks = breaks,
              alpha = 0.7, 
              id = "hex_id",
              textNA = "NA",
              popup.vars = c("Pct. Inundation" = "tot_pct_SLR_1ft")) +
  tm_view(colorNA = 'transparent',
          set.view = 9.5,
          view.legend.position = c("right", "bottom"))
```
<br/><br/>
As the maps indicate, sea level rise will primarily affect areas along Philadelphia’s major bodies of water: the Delaware River in the east, the Schuylkill River in the south, and Darby-Cobbs Creek in the southwest. Under the 1 foot sea level rise scenario, the areas most affected by sea level rise include Pennypack on the Delaware in the northeast, Fort Mifflin and an area east of the George C. Platt Bridge to the south, and the John Heinz National Wildlife Refuge in the southwest. As will be discussed below, these would have serious implications for bird biodiversity in Philadelphia, as these three sites are among the most biodiverse locations in the city.

The 2, 3, and 7 foot scenarios generally continue the trend established in the one foot scenario, with sea level rise especially impacting south Philadelphia. Most notable for bird biodiversity in Philadelphia is that the John Heinz Wildlife refuge, home to the second most bird biodiversity in the city, would be almost completely inundated under the 3 foot scenario, which is likely to occur within the next 50 years, according to NOAA. 
<br/><br/>

:::: {.columns}

::: {.column width="32%"}
###### **2 Feet of Sea Level Rise**
```{r 2 ft}
tmap_mode('view')

tm_shape(phl_ebird_hex_means) +
  tm_polygons(
              title = "Pct. Inundation",
              col = 'tot_pct_SLR_2ft', 
              palette = 'viridis', 
              style = 'fixed',
              breaks = breaks,
              alpha = 0.7, 
              id = "hex_id",
              textNA = "NA",
              popup.vars = c("Pct. Inundation" = "tot_pct_SLR_2ft"),
              legend.show = FALSE) +
  tm_view(colorNA = 'transparent',
          set.view = 9.5)
```
:::

::: {.column width="2%"}
<!-- empty column to create gap -->
:::

::: {.column width="32%"}
###### **3 Feet of Sea Level Rise**
```{r 3 ft}
tmap_mode('view')

tm_shape(phl_ebird_hex_means) +
  tm_polygons(
              title = "Pct. Inundation",
              col = 'tot_pct_SLR_3ft', 
              palette = 'viridis', 
              style = 'fixed',
              breaks = breaks,
              alpha = 0.7, 
              id = "hex_id",
              textNA = "NA",
              popup.vars = c("Pct. Inundation" = "tot_pct_SLR_3ft"),
              legend.show = FALSE) +
  tm_view(colorNA = 'transparent',
          set.view = 9.5)
```
:::

::: {.column width="2%"}
<!-- empty column to create gap -->
:::

::: {.column width="32%"}
###### **7 Feet of Sea Level Rise**
```{r 7 ft}
tmap_mode('view')

tm_shape(phl_ebird_hex_means) +
  tm_polygons(
              title = "Pct. Inundation",
              col = 'tot_pct_SLR_7ft', 
              palette = 'viridis', 
              style = 'fixed',
              breaks = breaks,
              alpha = 0.7, 
              id = "hex_id",
              textNA = "NA",
              popup.vars = c("Pct. Inundation" = 'tot_pct_SLR_7ft'),
              legend.show = FALSE) +
  tm_view(colorNA = 'transparent',
          set.view = 9.5)
```
:::

::::

## Findings

### Cluster Analysis
To identify high-priority areas for conservation management, we can turn to cluster analysis. In statistics, cluster analysis helps to identify groupings
of similar objects. In this case, we hope to identify a cluster of grid cells
associated with both high biodiversity and high sea level rise, which could
then be prioritized in conservation efforts. 

An easy way to identify possible clusters is to visualize the data on a scatterplot. However, an initial plot does not reveal any clusters; indeed, it highlights a handful of outliers that have high biodiversity and/or face a relatively high level of potential inundation, but outliers often make cluster analysis difficult. As the marginal density plots indicate, a small proportion of the cells
in the city-wide hexagon grid account for most of the biodiversity---only `r round(nrow(phl_ebird_hex_means |> filter(avg_unique_species > 50)) / nrow(phl_ebird_hex_means) *100, digits = 2)`% have observations of 50 or more unique species. Therefore, we know that Philadelphia\'s bird biodiversity clusters in a small number of neighborhoods relative to the total area of the city. Likewise, only `r round(nrow(phl_ebird_hex_means |> filter(tot_pct_SLR_1ft > 0)) / nrow(phl_ebird_hex_means) *100, digits = 2)`% of cells in Philadelphia will face any additional inundation under the 1 foot sea level rise scenario.

```{r first scatter}
ggMarginal(ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_1ft, y = avg_unique_species)) +
                            geom_point() +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "% SLR",
       y = "Avg. Unique Species") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)), type = "density", fill = "#41a65c", alpha = 0.2, col = "#41a65c") 
```

Even if we filter out any hexagons with no projected sea level rise impacted and no reported bird observations, we still cannot see obvious clusters.

```{r second scatter}
ggMarginal(ggplot((phl_ebird_hex_means |> filter(tot_pct_SLR_1ft > 0 & avg_unique_species > 0)),
                  aes(x = tot_pct_SLR_1ft, y = avg_unique_species)) +
                            geom_point() +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "% SLR",
       y = "Avg. Unique Species") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)), type = "density", fill = "#41a65c", alpha = 0.2, col = "#41a65c") 
```

Log transforming our filtered variables helps to normalize them somewhat, which is a prerequisite for most statistical analysis of clusters:
```{r scatter}
ggMarginal(ggplot((phl_ebird_hex_means |> filter(tot_pct_SLR_1ft > 0 & avg_unique_species > 0)), 
                  aes(x = log(tot_pct_SLR_1ft), y = log(avg_unique_species))) +
                            geom_point() +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "Log of % SLR",
       y = "Log of Avg. Unique Species") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)), type = "density", fill = "#41a65c", alpha = 0.2, col = "#41a65c")
```

Using these filtered, normal variables, we can attempt to apply a hierarchical clustering model to see if there are any underlying clusters not immediately visible to the human eye. Hierarchical clustering has a few advantages over other clustering approaches such as k-means, namely that it is less sensitive to outliers, more tolerant of non-globular clusters, and does not require us to designate the number of clusters in advance.^[Brusilovsky, Eugene. “K-Means Clustering.” MUSA 501/CPLN 671. Lecture. November 2022.] However, even using this clustering approach with the normalized variables, the `hdbscan` function in R returns 4 clusters exclusive of precisely the data points we are interested in: the outliers responsible for most of Philadelphia's biodiveristy. Although it reutns clusters with some confidence, these are clusters with low biodiversity and/or low impacts from sea level rise.

```{r hdbscan}
for_hdbscan = phl_ebird_hex_means |> 
                     st_drop_geometry() |> 
                      filter(tot_pct_SLR_1ft > 0 & avg_unique_species > 0) |>
                     select(tot_pct_SLR_1ft, avg_unique_species) |>
                     mutate(lg_tot_pct_SLR_1ft = log(tot_pct_SLR_1ft),
                            lg_avg_unique_species = log(avg_unique_species))|>
                     select(lg_tot_pct_SLR_1ft,
                            lg_avg_unique_species) |>
                    filter(!is.na(lg_tot_pct_SLR_1ft))


clusters = hdbscan(for_hdbscan, minPts = 4)
                   
for_hdbscan$clusters = as.character(clusters$cluster)
for_hdbscan$mem_prop = clusters$membership_prob * 100

for_hdbscan$clusters[for_hdbscan$clusters == 0] = "No Cluster"


ggplot(for_hdbscan, aes(x = lg_tot_pct_SLR_1ft, 
                        y = lg_avg_unique_species, 
                        color = clusters, 
                        alpha = mem_prop
                      )) +
                            geom_point(size = 2) +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "Log of % SLR",
       y = "Log of Avg. Unique Species",
       color = "Cluster",
       alpha = "Clust. Probability (%)") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_color_brewer(palette = 'Dark2') +
  scale_alpha(range = c(0.2, 1))
```

```{r classification}
#| include: false
jenks_free = classIntervals(phl_ebird_hex_means$avg_unique_species, style = 'jenks')

hclust_free = classIntervals(phl_ebird_hex_means$avg_unique_species, style = 'hclust')

kmeans_free = classIntervals(phl_ebird_hex_means$avg_unique_species, style = 'kmeans')

results = jenks.tests(jenks_free) ## has the highest goodness of fit! 
```

It appears, then, that our best option is to combine qualitative and statistical approaches to define our own cutoffs. First, we will distinguish between cells not projected to experience any additional inundation under the 1 foot sea level rise scenario. We will define these as "Miminal Risk". Then we will apply univariate classification to the average unique species measure of bird biodiversity. For this classification, we are using Jenks breaks (also known as Fisher natural breaks), partitioned into 10 classes. This is based on maximizing the Goodness of Variance Fit (GVF), which ranges from 0 to 1, and on Sturge's Rule for selecting the number of classes.^[Harkins, Ray. “Sturge's Rule: A Method for Selecting the Number of Bins in a Histogram.” Accendo Reliability, January 9, 2022. https://accendoreliability.com/sturges-rule-method-selecting-number-bins-histogram/.] Using the `classInt` package, we find that Jenks breaks have a GVF of `r round(results[2], digits = 3)`, higher than the GVFs for either a hierarchical clustering approach or k-means. (The Jenks natural breaks approach minimizes variance within classes and maximizes variance between classes.^[“Jenks Natural Breaks Optimization.” Wikipedia. Wikimedia Foundation, May 23, 2022. https://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization.]) This is not necessarily the ideal statistical approach for defining biodiversity hotspots, but is a good start for our purposes, and could be refined in future iterations of this work. We then classify the threat to biodiversity from 10 (highest) to 1 (lowest) based on these breaks:
```{{r}}
phl_ebird_hex_means = phl_ebird_hex_means |>
                        mutate(jenks_bio_risk = case_when(
                                                tot_pct_SLR_1ft >0 & avg_unique_species >= jenks_free$brks[10] ~ "10",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[10] & avg_unique_species >= jenks_free$brks[9] ~ "9",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[9] & avg_unique_species >= jenks_free$brks[8] ~ "8",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[8] & avg_unique_species >= jenks_free$brks[7] ~ "7",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[7] & avg_unique_species >= jenks_free$brks[6] ~ "6",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[6] & avg_unique_species >= jenks_free$brks[5] ~ "5",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[5] & avg_unique_species >= jenks_free$brks[4] ~ "4",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[4] & avg_unique_species >= jenks_free$brks[3] ~ "3",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[3] & avg_unique_species >= jenks_free$brks[2] ~ "2",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[2] & avg_unique_species >= jenks_free$brks[1] ~ "1",
                                                TRUE ~ "Minimal Risk"
                                                ))
```

Examining our self-defined clusters, we see that they better account for the issue of outliers, and in fact highlight the three hexagon cells which have exceptionally high biodiversity and face a threat of sea level rise:

```{r qualitative clust}
phl_ebird_hex_means = phl_ebird_hex_means |>
                        mutate(jenks_bio_risk = case_when(
                                                tot_pct_SLR_1ft >0 & avg_unique_species >= jenks_free$brks[10] ~ "10",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[10] & avg_unique_species >= jenks_free$brks[9] ~ "9",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[9] & avg_unique_species >= jenks_free$brks[8] ~ "8",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[8] & avg_unique_species >= jenks_free$brks[7] ~ "7",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[7] & avg_unique_species >= jenks_free$brks[6] ~ "6",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[6] & avg_unique_species >= jenks_free$brks[5] ~ "5",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[5] & avg_unique_species >= jenks_free$brks[4] ~ "4",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[4] & avg_unique_species >= jenks_free$brks[3] ~ "3",
                                                 tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[3] & avg_unique_species >= jenks_free$brks[2] ~ "2",
                                                tot_pct_SLR_1ft > 0 & avg_unique_species < jenks_free$brks[2] & avg_unique_species >= jenks_free$brks[1] ~ "1",
                                                TRUE ~ "Minimal Risk"
                                                ))

phl_ebird_hex_means$jenks_bio_risk = factor(phl_ebird_hex_means$jenks_bio_risk, levels = c("10", "9",
                                                                                           "8", "7",
                                                                                           "6", "5",
                                                                                           "4", "3",
                                                                                           "2", "1",
                                                                                           "Minimal Risk"))

ggplot(phl_ebird_hex_means, aes(x = tot_pct_SLR_1ft, 
                        y = avg_unique_species, 
                        color = jenks_bio_risk
                      )) +
                            geom_point(size = 2) +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "% SLR",
       y = "Avg. Unique Species",
       color = "Risk to Biodiversity") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_color_brewer(palette = "RdYlGn")
```

To make it easier to read, we can also log transform our data:
```{r log transform clusts}
ggplot(phl_ebird_hex_means, aes(x = log(tot_pct_SLR_1ft), 
                        y = log(avg_unique_species), 
                        color = jenks_bio_risk
                      )) +
                            geom_point(size = 2) +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "Log of % SLR",
       y = "Log of Avg. Unique Species",
       color = "Risk to Biodiversity") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_color_brewer(palette = "RdYlGn")
```

Based on these clusters, we can now map these data to see the spatial distribution of the threat to biodiversity in Philadelphia: 

###### **Sea Level Rise Risk to Biodiversity**
```{r tmap jenks clusters}
tmap_mode('view')

risk_palette = c("#A50026", "#D73027", "#F46D43", "#FDAE61", "#FEE08B", "#FFFFBF", "#D9EF8B", "#A6D96A", "#66BD63", "#1A9850", "#006837")

tm_shape(phl_ebird_hex_means) +
  tm_polygons(title = "Risk Level",
              col = 'jenks_bio_risk', 
              palette = risk_palette, 
              textNA = "Minimal Risk",
              style = 'cat',
              alpha = 0.7,
              id = "hex_id",
              popup.vars = c("Avg. Unique Species" = "avg_unique_species",
                             "% SLR (1ft)" = "tot_pct_SLR_1ft"))+
    tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')
```

<br/><br/>
To better identify the outliers, we can examine only those cells which scored a 10 for highest biodiversity. This also allows us to see how they compare in terms of the relative threat of sea level rise:
```{r high risk}
phl_ebird_hex_means |>
  filter(jenks_bio_risk == "10") |>
ggplot(aes(x = tot_pct_SLR_1ft, 
                        y = avg_unique_species,
           label = hex_id
                      )) +
                            geom_point(size = 3, fill = "#A50026") +
    geom_label_repel(size = 2.5, box.padding = 0.1, label.padding = 0.2) +
  labs(title = "Avg. Unique Species vs. % Sea Level Rise",
       subtitle = "1 ft. Sea Level Rise Scenario",
       x = "% SLR",
       y = "Avg. Unique Species",
       color = "Cluster") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

These top three cells correspond to the John Heinz National Wildlife Refuge (#137), Pennypack on the Delaware (#1319), and Bartram's Garden (#343). As the above plot indicates, John Heinz faces the highest threat of inundation, followed by Pennypack on the Delaware and then Bartram's Garden. Given that they are each also ranked in that order for biodiversity, John Heinz should be the #1 priority for conservation, followed by Pennypack on the Delaware and then Bartram's Garden. This analysis, then, effectively narrows down the city's bird biodiversity hotspots to identify those with the highest risk of impact from sea level rise in the coming two decades. These areas can be prioritized for conservation management specifically geared toward mitigating the worst impacts of sea level rise (or toward considering the possibility of managed retreat).

:::: {.columns}

::: {.column width="32%"}
**John Heinz (Hex #137)**
```{r heinz}
tmap_mode('view')

tm_shape(phl_ebird_hex_means |> filter(hex_id  == 137)) +
  tm_polygons(title = "Risk Level",
              col = 'jenks_bio_risk', 
              palette = risk_palette, 
              textNA = "Minimal Risk",
              style = 'cat',
              alpha = 0.2,
              id = "hex_id",
              popup.vars = c("Avg. Unique Species" = "avg_unique_species",
                             "% SLR (1ft)" = "tot_pct_SLR_1ft"),
              legend.show = FALSE)+
    tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')
```
:::

::: {.column width="2%"}
<!-- empty column to create gap -->
:::

::: {.column width="32%"}
**Pennypack on the Delaware (Hex #1319)**
```{r pennypack}
tmap_mode('view')

tm_shape(phl_ebird_hex_means |> filter(hex_id == 1319)) + 
                  tm_polygons(title = "Risk Level",
              col = 'jenks_bio_risk', 
              palette = risk_palette, 
              textNA = "Minimal Risk",
              style = 'cat',
              alpha = 0.2,
              id = "hex_id",
              popup.vars = c("Avg. Unique Species" = "avg_unique_species",
                             "% SLR (1ft)" = "tot_pct_SLR_1ft"),
              legend.show = FALSE)+
    tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')
```
:::

::: {.column width="2%"}
<!-- empty column to create gap -->
:::

::: {.column width="32%"}
**Bartram's Garden (Hex #343)**
```{r bartrams}
tmap_mode('view')

tm_shape(phl_ebird_hex_means |> filter(hex_id == 343)) + 
                  tm_polygons(title = "Risk Level",
              col = 'jenks_bio_risk', 
              palette = risk_palette, 
              textNA = "Minimal Risk",
              style = 'cat',
              alpha = 0.2,
              id = "hex_id",
              popup.vars = c("Avg. Unique Species" = "avg_unique_species",
                             "% SLR (1ft)" = "tot_pct_SLR_1ft"),
              legend.show = FALSE)+
    tm_view(view.legend.position = c("right", "bottom"),
            colorNA = 'transparent')
```
:::

::::
<br/><br/>

## Conclusions

### Key Takeaways

This project aimed to explore whether citizen science data from eBird could support an analysis of the potential impacts of sea level rise on bird biodiversity in Philadelphia. Based on the above analysis, it seems that these data could be used in such a way. Although there are still many metholodigical considerations to resolve and improve, this project is a good test case to show that such an approach is feasible. Moreover, despite the lack of statistical sophistication, it shows the utility of even rudimentary tools in answering these questions. Indeed, sophisticated metehods like clustering analysis may be overkill for the task at hand.

Furthermore, as more resources are invested in tools like eBird and more data are collected, analyses like these will become easier and more robust. Some of the issues with this particular project relate to insufficient data, for instance, and should become irrelevant as eBird data are reported more and more consistently. Additionally, issues related to statistical rigor could be ameliorated by developing a consistent, reproducible workflow in conjunction with specialists. As tools like eBird became more commonplace and established, there will be a greater and greater incentive for governments, research institutions, and so forth to invest in making them reliable, sustainable, and reproducible.

As Philadelphia prepares for inevitable sea level rise, tools like this one can help local institutions of government make better decisions about conversation. For instance, knowing that [sea walls pose an outsize threat to bird biodiversity](https://www.audubon.org/news/the-best-defense-against-sea-level-rise-leaves-little-room-birds), understanding the geography of biodiversity in the city can help guide choices between habitat restoration and sea wall construction, or motivate the avoidance of sea walls in some parts of the city.[^17]

[^17]: Dugan, J.E., Hubbard, D.M., Rodil, I.F., Revell, D.L. and Schroeter, S. (2008), Ecological effects of coastal armoring on sandy beaches. Marine Ecology, 29: 160-170. https://doi.org/10.1111/j.1439-0485.2008.00231.x

#### Prediction vs. Monitoring

At the outset of this project, I hoped to model species distribution in Philadelphia and predict how it would be impacted by sea level rise. In the course of my research, though, I came to the conclusion that this was neither feasible nor desirable, for reasons that are worth stating.

First, the quality of available data was insufficient for predictive modeling at an urban scale. Presence-only or presence/absence distribution models both rely on point data for species observations combined with raster data for landscape variables such as land cover. Because of the way citizen science data in eBird is reported, the observations available did not include adequately precise coordinate data for this approach, nor would it have been feasible to reconcile the different landscape variables given their diverse spatial scales.

Second, environmental modeling is notoriously complex, even for single species with ideal data. It is impossible to divorce the impact of sea level rise alone on biodiversity from other confounding factors like [coastal modification, saltwater intrusion, increased rainfall, and water pollution,](https://explorer.audubon.org/explore/conservation-challenges?zoom=3&x=1306099.1620122588&y=2810864.562197212) let alone less proximate factors like changes in human population density and land use or the arrival of invasive species. Furthermore, as Pilkey and Pilkey point out, even if the scale of such impacts could be measured, it is difficult to account for ordering complexity: the unpredictable differences in impact depending on the order in which events occur.[^18] As Jimenez-Valverde et al., explain, prediction via species distribution modeling only works "if correlation structures are stable and consistent across different landscapes and time periods".[^19] Given the aforementioned rapid change of key factors like habitat fragmentation, buildout, and land cover in urban environments, attempts at predictive modeling of biodiversity for cities may do more harm than good by obscuring the underlying uncertainty.

[^18]: Pilkey, Orrin H., and Linda Pilkey-Jarvis. *Useless Arithmetic: Why Environmental Scientists Can't Predict the Future*. New York: Columbia University Press, 2009. 

[^19]: Jimenez-Valverde et al., 2009.

With that in mind, I follow Orrin Pilkey in suggesting that, in this context, monitoring and adapting are far more important than predicting.[^20] Given that the general scope and direction of sea level rise and other threats to biodiversty are known, citizen science data employed in projects like this one can help cities keep tabs on their biodiversity and make adjustments to support it, without relying on dubious predictive models.

[^20]: *Useless Arithmetic*, 2007.

Finally, the use of citizen science data for management can help to engage community memebers in conservation and stewardship by giving them a defined, valuable role to play in efforts to support local biodiversity. Philadelphia already has a strong citizen science and stewardship community in the form of grops like the [City Nature Challenge](https://cncphilly.org/), [Bird Philly](https://birdphilly.org/cgi-sys/suspendedpage.cgi), [Philly Naturalists](https://phillynaturalists.org/), and the [Master Watershed Steward program](https://extension.psu.edu/programs/watershed-stewards/counties/philadelphia). Employing data that they collect gives them a demonstrable stake in conservation efforts and can help to justify investment in a virtuous cycle of municipal support for local stewardship and citizen science helping to advance municipal conservation efforts and so forth.

### Next Steps

#### Improve Statistical Rigor

A key next step for this project would be employing more rigorous statistical tools to analyze species richness and distribution. As stated in the Data Wrangling and Exploration section, calculating a rarefaction curve using eBird data would be a more accurate way of estimating total species richness. There are a variety of ways to accomplish this; the [`vegan` package in R](https://github.com/vegandevs/vegan), for example, includes a function to calculate rarefaction curves. However, this requires an understanding of quantitative ecology beyond what I am currently capable of. To this end, if I were to repeat this project, I would want to recruit a quantitative ecologist to help improve the statistical and methodological rigor of my analysis.

Furthermore, it would be worthwhile to incorporate a sophisticated analysis of spatial clustering for biodiversity. In an early version of this project, I attempted to calculate global and local Moran's I values to analyze the distribution of biodiversity for [spatial autocorrelation](https://www.sciencedirect.com/topics/computer-science/spatial-autocorrelation). However, the patterns that I found were unexpected and had p-values that indicated that they were not statistically significant. I suspect that this is related to extreme habitat fragmentation and abrupt land use changes in urban contexts, as well as my choice to use hexagon bins to accommodate issues with the point data from eBird. Again, a quantitative ecologist who focuses on urban contexts would likely better understand these issues and be able to provide guidance.

#### Develop a Workflow

One of the primary aims of this project is to demonstrate replicability. Nothing about the data used is unique to Philadelphia; in theory, this project could be replicated in any city with sufficient eBird data and sea level rise projections. (The eBird data could even be used in isolation for projects unrelated to sea level rise.) If a proper workflow were developed, it would be possible to easily apply these tools in other cities to support conservation decisions, including in cities that otherwise lack substantial data on biodiversity. In order to facilitate this, it would be worth 1) solidifying a consistent workflow, 2) developing some kind of guide such as [the one prepared by the Cornell Ornithology Lab for handling eBird data](https://cornelllabofornithology.github.io/ebird-best-practices/), and 3) potentially preparing an R package to simplify this workflow and make it more consistent, much like Cornell has done with [their `auk` package](https://rdrr.io/github/mstrimas/auk/#vignettes). Together, these tools could help cities around the globe more effectively and consistently analyze their local biodiversity and potential threats to it.

#### Incorporate More Data

There are a variety of opportunities to incorporate more nuanced, diverse data into an analysis like this. Three primary opportunities are 1) more species observations other than birds, 2) common ecology-related raster data, and 3) datasets specific to urban contexts.

Biodiversity consists of more than birds. Although it is nearly impossible to account for the full spectrum of biodiversity in an urban contexts (how, for example, can we reliably sample microorganisms at any meaningful scale?), measures of biodiversity such as the [City Biodiversity Index](https://www.cbd.int/doc/publications/cbd-ts-98-en.pdf) incorporate other biotic kingdom, namely arthropods and vascular plants.[^21] Expanding beyond an analysis of avian biodiversity can offer a more complex understanding of a city's ecosystems, which is vital in planning responses to systems as complex as climate change. To accomplish this, future analysis could incorporate data from platforms such as [iNaturalist](https://www.inaturalist.org/pages/about), which collects and publishes citizen science data on all biota, not just birds. One example of a potential application of this is [Urban Shift's report on conservation planning in San Jose, Costa Rica](https://cities-urbanshift.s3.eu-west-3.amazonaws.com/baseline-indicators/biodiversity/reports/UrbanShift-Biodiversity-SanJose.html).

[^21]: “Handbook on the Singapore Index on Cities’ Biodiversity.” Accessed December 20, 2022. https://www.cbd.int/doc/publications/cbd-ts-98-en.pdf. 

Another possible supplement to biodiversity data for conservation purposes are the standard raster layers often used in biodiversity analyses such as species distribution modeling. This includes data such as tree cover, land cover type, distance to water, altitude, slope, aspect, soil type, and more. Many (if not all) of these data are available publicly, especially in the United States, from sources like the [United States Geological Service](https://www.usgs.gov/products/data) or [Pennsylvania Spatial Data Access](https://www.pasda.psu.edu/). The primary challenge with these datasets is reconciling their different resolutions in order to apply them in the desired context.

Finally, given the urban context of this evaluation, it would be worthwhile to incorporate measures of biodiveristy disturbance associated with urbanization, such as habitat fragmentation, impervious surface cover, and human population density. A major challenge here, however, is that such measures change on a much more granular scale in urban contexts than in "natural" contexts where ecological analyses are commonly carried out. Similarly, many urban interventions to support biodiversity, such as pocket parks or pollinator gardens, happen at scales so small that they would be hard to meaningfully factor into an analysis such as this one.

One important caveat to this discussion, however, is that any additional data must be motivated by a clear use. First, much of these data likely covaries, raising the possibility of redundance. In particular, the premise of choosing indicator species is to simplifying ecological monitoring by using an effective proxy. Introducing too much new data may defeat the purpose of the exercise. Second (and this is especially important in the case of Philadelphia), a main motivation of this project is to find a cost-effective, scalable means of exploring the impact of sea level rise on biodiversity. Introducing more data raises the prospect of diminishing marginal returns: that is, it may exceed the capacity of under-resourced local governments to actually analyze and use the data without actually producing a more robust understanding of conservation challenges. In sum, more data is useful, but only insofar as it contributes to under-resourced cities' ability to better plan for conservation.

#### Interace with Government and Community

Above all else, the best next step would be to connect with members of the local government and various community organizations to identify potential applications of an analysis like this. Currently, this project amounts to an intellectual exercise. However, by speaking with members of the local parks department, conservation organizations, or community stewardship groups, it may be possible to find ways to use this analysis to support conservation work that they are currently doing or to motivate new work.
